---
title: "Data and Measurement"
output:
  html_document:
    theme: 
       bootswatch: minty
    df_print: kable
    code_folding: hide 
---

```{r, echo = F}
library(formatR)
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=10),tidy=TRUE)

```


# Tutorial 6

In this tutorial we will use the data set "SAQ.sav". This dataset includes 23 variables measured on a 5-point Likert scale and contains data from 2,571 participants. The items included are:

1. Statistics makes me cry.
2. My friends will think I’m stupid for not being able to cope with SPSS.
3. Standard deviations excite me.
4. I dream that Pearson is attacking me with correlation coefficients.
5. I don’t understand statistics.
6. I have little experience of computers.
7. All computers hate me.
8. I have never been good at mathematics.
9. My friends are better at statistics than me.
10. Computers are useful only for playing games.
11. I did badly at mathematics at school.
12. People try to tell you that SPSS makes statistics easier to understand but it doesn’t.
13. I worry that I will cause irreparable damage because of my incompetenece with computers.
14. Computers have minds of their own and deliberately go wrong whenever I use them.
15. Computers are out to get me.
16. I weep openly at the mention of central tendency.
17. I slip into a coma whenever I see an equation.
18. SPSS always crashes when I try to use it.
19. Everybody looks at me when I use SPSS.
20. I can’t sleep for thoughts of eigen vectors.
21. I wake up under my duvet thinking that I am trapped under a normal distribution.
22. My friends are better at SPSS than I am.
23. If I’m good at statistics my friends will think I’m a nerd.


##  {.tabset .tabset-fade .tabset-pills}
### Exercise  

1. Load the data into the environment. If you use the read.spss function, set the use.value.labels argument to FALSE to avoid converting numeric variables (with value labels) to factors, since the functions we will use (fa()) require numeric variables.

2. You already know this data set from Tutorial 5, so we will skip the step "Exploring the data set".

3. Run the Bartlett test for sphericity using the cortest.bartlett function from the psych package. Interpret the results. Note that you can enter the data set (instead of a correlation matrix) directly into the first argument.

4. Apply the Kaiser-Meyer-Olkin measure using the KMO() function from the psych package. Interpret the results.

5. Draw a scree plot using the VSS.scree() function from the psych package. How many factors should be extracted according to the inflexion point?

6. Perform an exploratory factor analysis using the fa() function from the psych package. Determine the nfactors to be extracted based on your answer to the previous question. Set the argument fm to "pa" (principal axis factorization), set max.iter = 100 and use a orthogonal rotation (e.g..rotate = "varimax"). Save the results in an object.

7. Interpret the results (including the model fit indices). You can use the annotated results from the book by Watkins (2021), e.g. p.93).

8. Visualize the results using the fa.diagram() function from the psych.

9. Extract the loadings for the third item (question_3) for all factors, square the loadings and sum them. Does the value match the value in column h2 in the model results? (You can also extract the communalities by entering communality with the $ sign in your saved model results)

10. Plot the residuals after extraction using the residuals() function of the psych package (you can set diag = FALSE and na.rm = TRUE). What should we pay attention to in this plot?

